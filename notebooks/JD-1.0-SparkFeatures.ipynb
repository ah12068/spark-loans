{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:47.136187Z",
     "start_time": "2020-05-21T11:21:46.976388Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DateType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, MinMaxScaler, VectorAssembler\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:47.140719Z",
     "start_time": "2020-05-21T11:21:47.137786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = f'../data/interim/loans_clean_spark/part-*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:47.145394Z",
     "start_time": "2020-05-21T11:21:47.142603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "distinct_count = 'distinct_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:47.149691Z",
     "start_time": "2020-05-21T11:21:47.147028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Id = ['account_id']\n",
    "target = ['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:49.718790Z",
     "start_time": "2020-05-21T11:21:47.152891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Features').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:49.744935Z",
     "start_time": "2020-05-21T11:21:49.722756Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_nuniques(data):\n",
    "    nuniques = data.agg(*(F.countDistinct(F.col(column)).alias(column) for column in data.columns))\n",
    "    nuniques = nuniques.toPandas().transpose()\n",
    "    nuniques.columns = [distinct_count]\n",
    "    \n",
    "    return nuniques\n",
    "\n",
    "def binarize(data, column):\n",
    "    output_name = f'binary_{column}'\n",
    "    \n",
    "    encoder = StringIndexer(\n",
    "    inputCol=column,\n",
    "    outputCol=output_name\n",
    "    )\n",
    "    \n",
    "    model = encoder.fit(data)\n",
    "    binarized_data = model.transform(data)\n",
    "    \n",
    "    binarized_data = binarized_data.drop(column)\n",
    "    \n",
    "    return binarized_data\n",
    "\n",
    "def create_dummies(data, identifier, column):\n",
    "    categories = data.select(column).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    exprs = [F.when(F.col(column) == category, 1).otherwise(0).alias(f'{column}_{category}') for category in categories]\n",
    "    \n",
    "    return data.select(identifier, *exprs)\n",
    "\n",
    "def min_max_scale(data, column):\n",
    "    feature_name = f'feature_{column}'\n",
    "    scaled_name = f'scaled_{column}_vec'\n",
    "    feature_assembler = VectorAssembler(\n",
    "        inputCols=[column],\n",
    "        outputCol=feature_name\n",
    "    )\n",
    "    scaler = MinMaxScaler(\n",
    "        inputCol=feature_name,\n",
    "        outputCol=scaled_name\n",
    "    )\n",
    "    assembler = feature_assembler.transform(data)\n",
    "    model = scaler.fit(assembler)\n",
    "    encoded_data = model.transform(assembler)\n",
    "    \n",
    "    unlist = F.udf(lambda x: float(list(x)[0]),DoubleType())\n",
    "    correct_datatype_col = f'scaled_{column}'\n",
    "    encoded_data = encoded_data.withColumn(correct_datatype_col, unlist(f'{scaled_name}'))\n",
    "    \n",
    "    encoded_data = encoded_data.drop(*[column, feature_name, scaled_name])\n",
    "    \n",
    "    return encoded_data\n",
    "\n",
    "def get_features(data, spark_session, target):\n",
    "    output_name = f'features'\n",
    "    features = VectorAssembler(\n",
    "    inputCols = [var for var in data.columns if var not in target],\n",
    "    outputCol = output_name\n",
    "    )\n",
    "    \n",
    "    output = features.transform(data)\n",
    "    \n",
    "    output.createTempView(output_name)\n",
    "    \n",
    "    finalised_data = spark_session.sql(f'''\n",
    "    select\n",
    "    features,\n",
    "    {target}\n",
    "    from {output_name}\n",
    "    ''')\n",
    "    \n",
    "    return finalised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:53.629876Z",
     "start_time": "2020-05-21T11:21:49.746230Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = spark.read.csv(\n",
    "    path,\n",
    "    inferSchema=True,\n",
    "    header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:53.648820Z",
     "start_time": "2020-05-21T11:21:53.631717Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: integer (nullable = true)\n",
      " |-- installment: double (nullable = true)\n",
      " |-- loan_amount: double (nullable = true)\n",
      " |-- interest_rate: double (nullable = true)\n",
      " |-- term: integer (nullable = true)\n",
      " |-- purpose: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_income: integer (nullable = true)\n",
      " |-- employment_length: string (nullable = true)\n",
      " |-- public_records: double (nullable = true)\n",
      " |-- delinquency_2y: double (nullable = true)\n",
      " |-- inquiries_6m: string (nullable = true)\n",
      " |-- open_accounts: double (nullable = true)\n",
      " |-- debt_to_income: double (nullable = true)\n",
      " |-- credit_card_usage: double (nullable = true)\n",
      " |-- credit_card_balance: double (nullable = true)\n",
      " |-- total_current_balance: double (nullable = true)\n",
      " |-- nr_accounts: double (nullable = true)\n",
      " |-- credit_score: integer (nullable = true)\n",
      " |-- credit_age_years: integer (nullable = true)\n",
      " |-- class: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:57.130723Z",
     "start_time": "2020-05-21T11:21:53.650560Z"
    }
   },
   "outputs": [],
   "source": [
    "nuniques = data.agg(*(F.countDistinct(F.col(column)).alias(column) for column in data.columns)).toPandas().transpose()\n",
    "nuniques.columns = [distinct_count]\n",
    "\n",
    "binary_vars = [var for var in nuniques[nuniques.values == 2].index if var not in target]\n",
    "categorical_vars = [var for var in nuniques[nuniques.values <=5].index if var not in target+binary_vars]\n",
    "numerical_vars = [var for var in data.columns if var not in Id + target + categorical_vars + binary_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:21:57.930965Z",
     "start_time": "2020-05-21T11:21:57.132682Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for column in binary_vars:\n",
    "    data = binarize(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:09.405521Z",
     "start_time": "2020-05-21T11:21:57.932117Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in categorical_vars:\n",
    "    dummy_var = create_dummies(data, Id[0], column)\n",
    "    \n",
    "    data = data.join(dummy_var, data[Id[0]] == dummy_var[Id[0]])\n",
    "    data = data.drop(dummy_var[Id[0]])\n",
    "    data = data.drop(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:41.501532Z",
     "start_time": "2020-05-21T11:22:09.407967Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in numerical_vars:\n",
    "    data = min_max_scale(data, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:41.509860Z",
     "start_time": "2020-05-21T11:22:41.502902Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(*Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:41.520649Z",
     "start_time": "2020-05-21T11:22:41.511219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: integer (nullable = true)\n",
      " |-- binary_term: double (nullable = false)\n",
      " |-- purpose_other: integer (nullable = false)\n",
      " |-- purpose_debt_consolidation: integer (nullable = false)\n",
      " |-- purpose_credit_card: integer (nullable = false)\n",
      " |-- home_ownership_own: integer (nullable = false)\n",
      " |-- home_ownership_other: integer (nullable = false)\n",
      " |-- home_ownership_mortgage: integer (nullable = false)\n",
      " |-- home_ownership_rent: integer (nullable = false)\n",
      " |-- employment_length_7to9: integer (nullable = false)\n",
      " |-- employment_length_10plus: integer (nullable = false)\n",
      " |-- employment_length_1to3: integer (nullable = false)\n",
      " |-- employment_length_less1: integer (nullable = false)\n",
      " |-- employment_length_4to6: integer (nullable = false)\n",
      " |-- inquiries_6m_1_inquiry: integer (nullable = false)\n",
      " |-- inquiries_6m_2plus_inquiry: integer (nullable = false)\n",
      " |-- inquiries_6m_no_inquiry: integer (nullable = false)\n",
      " |-- scaled_installment: double (nullable = true)\n",
      " |-- scaled_loan_amount: double (nullable = true)\n",
      " |-- scaled_interest_rate: double (nullable = true)\n",
      " |-- scaled_annual_income: double (nullable = true)\n",
      " |-- scaled_public_records: double (nullable = true)\n",
      " |-- scaled_delinquency_2y: double (nullable = true)\n",
      " |-- scaled_open_accounts: double (nullable = true)\n",
      " |-- scaled_debt_to_income: double (nullable = true)\n",
      " |-- scaled_credit_card_usage: double (nullable = true)\n",
      " |-- scaled_credit_card_balance: double (nullable = true)\n",
      " |-- scaled_total_current_balance: double (nullable = true)\n",
      " |-- scaled_nr_accounts: double (nullable = true)\n",
      " |-- scaled_credit_score: double (nullable = true)\n",
      " |-- scaled_credit_age_years: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:41.532942Z",
     "start_time": "2020-05-21T11:22:41.530100Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = get_features(data, spark, target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T11:22:41.537670Z",
     "start_time": "2020-05-21T11:22:41.535167Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
